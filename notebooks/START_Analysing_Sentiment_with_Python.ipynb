{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b138665f",
      "metadata": {
        "id": "b138665f"
      },
      "source": [
        "# START.. Analysing Sentiment with Python\n",
        "\n",
        "February 2023, [Southampton Digital Humanities](http://digitalhumanities.soton.ac.uk/).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94cc5657",
      "metadata": {
        "id": "94cc5657"
      },
      "source": [
        "### Purpose\n",
        "\n",
        "Processing text is a good way into learning a new programming language. In this START session, learn how to use Python (a general purpose programming language) to analyse textual data.\n",
        "\n",
        "In this lesson you will learn to conduct ‘sentiment analysis’ on texts and to interpret the results. This is a form of exploratory data analysis based on natural language processing. You will learn to install all appropriate software and to build a reusable program that can be applied to your own texts.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Be Kind\n",
        "\n",
        "\n",
        "Ideally, don't use my colab notebook (and hence google resources) by make your own. To do this:\n",
        "\n",
        "1. Copy this notebook to your Google Drive to keep it and save your changes. (File -> Save a Copy in Drive)\n",
        "2. Make sure you're running the notebook in Google Chrome."
      ],
      "metadata": {
        "id": "y0BROlfJQ9ex"
      },
      "id": "y0BROlfJQ9ex"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup"
      ],
      "metadata": {
        "id": "YW7jg9zoqji2"
      },
      "id": "YW7jg9zoqji2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5804112a",
      "metadata": {
        "id": "5804112a"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('vader_lexicon')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cbabef9d",
      "metadata": {
        "id": "cbabef9d"
      },
      "source": [
        "In this tutorial, you will be using Python along with a few tools from the Natural Language Toolkit (NLTK) to generate sentiment scores from e-mail transcripts. To do this, you will first learn how to load the textual data into Python, select the appropriate NLP tools for sentiment analysis, and write an algorithm that calculates sentiment scores for a given selection of text. We’ll also explore how to adjust your algorithm to best fit your research question.\n",
        "\n",
        "The [Natural Language Toolkit](https://www.nltk.org/) or NLTK, is an open-source Python library that enable us to apply natural langauge processing techniques to human language text data. \n",
        "\n",
        "In the step above we import the NLTK toolkit into the notebook so that we can pull the necessary features we need. `punkt` is a tokenizer, which means it breaks down text data into smaller components such as sentences or words to analyse."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "990c63c0",
      "metadata": {
        "id": "990c63c0"
      },
      "outputs": [],
      "source": [
        "pip install vaderSentiment-fr"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "837e7a2b",
      "metadata": {
        "id": "837e7a2b"
      },
      "source": [
        "In the above setup we import the French version of [VADER](https://www.nltk.org/_modules/nltk/sentiment/vader.html) (which we'll use later).\n",
        "\n",
        "[VADER](https://www.nltk.org/_modules/nltk/sentiment/vader.html) is a sentiment intensity tool added to NLTK in 2014. Unlike other techniques that require training on related text before use, VADER is ready to go for analysis without any special setup. VADER is unique in that it makes fine-tuned distinctions between varying degrees of positivity and negativity. For example, VADER scores “comfort” moderately positively and “euphoria” extremely positively. It also attempts to capture and score textual features common in informal online text such as capitalizations, exclamation points, and emoticons."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d32408af",
      "metadata": {
        "id": "d32408af"
      },
      "outputs": [],
      "source": [
        "pip install python-Levenshtein"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
      ],
      "metadata": {
        "id": "ZHFP8Lyg81a-"
      },
      "id": "ZHFP8Lyg81a-",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Alongside measuring the polarity of a text, VADAR also can analyse intensity of a text. In the step above we are importing this feature from the VADAR package."
      ],
      "metadata": {
        "id": "sjq8PXwqoRD6"
      },
      "id": "sjq8PXwqoRD6"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Simple Usage"
      ],
      "metadata": {
        "id": "rK_qQKHI9IOe"
      },
      "id": "rK_qQKHI9IOe"
    },
    {
      "cell_type": "code",
      "source": [
        "sid = SentimentIntensityAnalyzer()"
      ],
      "metadata": {
        "id": "tQZ6UDc49Qg4"
      },
      "id": "tQZ6UDc49Qg4",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Above, we initialize VADER so we can use it within our Python script. By doing this we have given our new variable `sid` all of the features of the VADER sentiment analysis code. It has become our sentiment analysis tool, but by a shorter name.\n",
        "\n",
        "Next, we need to store some text we want to analyze in a place `sid` can access. In Python, we can store a single sequence of text as a string variable.\n",
        "\n",
        "In this case, we'll use some text from the Enron Email Corpus, more information on which [can be found here](https://programminghistorian.org/en/lessons/sentiment-analysis#a-case-study-the-enron-e-mail-corpus)."
      ],
      "metadata": {
        "id": "OZrTYv-b9WJ6"
      },
      "id": "OZrTYv-b9WJ6"
    },
    {
      "cell_type": "code",
      "source": [
        "message_text = '''I think we are making great progress on the systems side.  I would like to set a deadline of November 10th to have a plan on all North American projects (I'm ok if fundementals groups are excluded) that is signed off on by commercial, Sally's world, and Beth's world.  When I say signed off I mean that I want signitures on a piece of paper that everyone is onside with the plan for each project.  If you don't agree don't sign. If certain projects (ie. the gas plan) are not done yet then lay out a timeframe that the plan will be complete.  I want much more in the way of specifics about objectives and timeframe.\n",
        "\n",
        "Thanks for everyone's hard work on this.'''"
      ],
      "metadata": {
        "id": "7JADJ-N59db_"
      },
      "id": "7JADJ-N59db_",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now you are ready to process the text.\n",
        "\n",
        "To do this, the text (message_text) must be input into the tool (sid) and the programme must be run. We are interested in the ‘polarity score’ of the sentiment analyzer, which gives us a score that is either positive or negative. This feature is built into VADER and can be requested on demand.\n"
      ],
      "metadata": {
        "id": "Lt5yhLx19lT6"
      },
      "id": "Lt5yhLx19lT6"
    },
    {
      "cell_type": "code",
      "source": [
        "print(message_text)"
      ],
      "metadata": {
        "id": "__bY_3hVgwCN"
      },
      "id": "__bY_3hVgwCN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(message_text)\n",
        "scores = sid.polarity_scores(message_text)\n",
        "\n",
        "# Here we loop through the keys contained in scores (pos, neu, neg, and compound scores) and print the key-value pairs on the screen\n",
        "for key in sorted(scores):\n",
        "        print('{0}: {1}, '.format(key, scores[key]), end='')"
      ],
      "metadata": {
        "id": "kneJ1hVH9q76"
      },
      "id": "kneJ1hVH9q76",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The output should look like this:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "Like you, I am getting very frustrated with this process. I am genuinely trying to be as reasonable as possible. I am not trying to \"hold up\" the deal at the last minute. I'm afraid that I am being asked to take a fairly large leap of faith after this company (I don't mean the two of you -- I mean Enron) has screwed me and the people who work for me.\n",
        "compound: -0.3804, neg: 0.093, neu: 0.836, pos: 0.071,\n",
        "```\n",
        "\n",
        "Note that `neg`, `neu`, and `pos` are scored between 0 and 1, and `compound` is scored between -1 and 1. For more on how the `compound` score is calculated, see \"[How is the Vader 'compound' polarity score calculated in Python NLTK?](https://stackoverflow.com/questions/40325980/how-is-the-vader-compound-polarity-score-calculated-in-python-nltk)\"\n"
      ],
      "metadata": {
        "id": "H0c4_pmE91DL"
      },
      "id": "H0c4_pmE91DL"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Do we agree with the outcome?**\n",
        "\n",
        "What does this imply, to you, about the way that sentiment might be expressed within a professional e-mail context? How might you define your threshold values when the text expresses emotion in a more subtle or courteous manner? Do you think that sentiment analysis is an appropriate tool for our exploratory data analysis?"
      ],
      "metadata": {
        "id": "nNNkcM_s-glo"
      },
      "id": "nNNkcM_s-glo"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Challenge Task\n",
        "\n",
        "Try replacing the contents of `message_text` with the following strings and re-running the program. Don’t forget to surround each text with three single quotation marks when assigning it to the message_text variable (as in: `message_text = '''some words'''`). \n",
        "\n",
        "**Before running the program**, guess (and write in the chat!) what you think the sentiment analysis outcome will be: positive, or negative? How strongly positive or negative?\n",
        "\n",
        "\n",
        "```\n",
        "Looks great.  I think we should have a least 1 or 2 real time traders in Calgary.\n",
        "```\n",
        "\n",
        "```\n",
        "I think we are making great progress on the systems side.  I would like to set a deadline of November 10th to have a plan on all North American projects (I'm ok if fundementals groups are excluded) that is signed off on by commercial, Sally's world, and Beth's world.  When I say signed off I mean that I want signitures on a piece of paper that everyone is onside with the plan for each project.  If you don't agree don't sign. If certain projects (ie. the gas plan) are not done yet then lay out a timeframe that the plan will be complete.  I want much more in the way of specifics about objectives and timeframe.\n",
        "\n",
        "Thanks for everyone's hard work on this.\n",
        "```\n",
        "\n",
        "Try it a third time with some text from an English language news website. What results did you get for each? Do you agree with the outcomes?"
      ],
      "metadata": {
        "id": "t_MJ3Xsi99tp"
      },
      "id": "t_MJ3Xsi99tp"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### French Language Scenario"
      ],
      "metadata": {
        "id": "d4Wq0_1I9MyJ"
      },
      "id": "d4Wq0_1I9MyJ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this scenario, we explore the variations created when translations are  conducted by a human and a machine between English and French. In particular, this notebook is interested in exploring how AI translation software interprets emotion and whether the AI translator can recreate emotion similarly to a human translator. For the human generated data, the sources range from news articles and press releases, fictional literature, and film subtitling which were available in both french and english; and for the machine generated data, the english versions were processed through DeepL.\n",
        "\n",
        "This section of the notebook is based on work produced in spring/summer 2022 by [Isobel Lester](https://github.com/ic-lester/) as part of a [Digital Humanities Internship](https://www.southampton.ac.uk/study/facilities/digital-humanities-facilities) funded by the [School of Humanities](https://www.southampton.ac.uk/about/faculties-schools-departments/school-of-humanities).\n"
      ],
      "metadata": {
        "id": "-l-wSAs0_JAM"
      },
      "id": "-l-wSAs0_JAM"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "fdf6952a",
      "metadata": {
        "id": "fdf6952a"
      },
      "outputs": [],
      "source": [
        "from vaderSentiment_fr.vaderSentiment import SentimentIntensityAnalyzer   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "a429d37e",
      "metadata": {
        "id": "a429d37e"
      },
      "outputs": [],
      "source": [
        "SIA = SentimentIntensityAnalyzer()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e4ae265",
      "metadata": {
        "id": "3e4ae265"
      },
      "source": [
        "In this step, we import VADER's French language sentiment analyser and put it into the variable `SIA`."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Simple Analysis"
      ],
      "metadata": {
        "id": "4e8C_iARC5k7"
      },
      "id": "4e8C_iARC5k7"
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this simple example, we anaylse two French translations of the phrase \"Parties at the Tuñon's always ended awfully late\", one translated by a person, another by a machine translator."
      ],
      "metadata": {
        "id": "f-KDqeYshkLN"
      },
      "id": "f-KDqeYshkLN"
    },
    {
      "cell_type": "code",
      "source": [
        "human_text = '''Les fêtes chez les Tuñon se terminaient toujours affreusement tard'''"
      ],
      "metadata": {
        "id": "t8219FpwC-RK"
      },
      "id": "t8219FpwC-RK",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "machine_text = '''Les fêtes chez les Tuñons se terminaient toujours très tard'''"
      ],
      "metadata": {
        "id": "UeQFOKU9DYFI"
      },
      "id": "UeQFOKU9DYFI",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores_human_text = SIA.polarity_scores(human_text)\n",
        "\n",
        "for key in sorted(scores_human_text):\n",
        "        print('Human scores: {0}: {1}, '.format(key, scores_human_text[key]), end='')"
      ],
      "metadata": {
        "id": "QLLN-gmaDhbB"
      },
      "id": "QLLN-gmaDhbB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores_machine_text = SIA.polarity_scores(machine_text)\n",
        "\n",
        "for key in sorted(scores_machine_text):\n",
        "        print('Machine scores: {0}: {1}, '.format(key, scores_machine_text[key]), end='')"
      ],
      "metadata": {
        "id": "tfo2O9OmDoDE"
      },
      "id": "tfo2O9OmDoDE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As Isobel writes:\n",
        "\n",
        "> In this extract, the human and machine translator has used different adjectives (awfully late vs. very late) that portray the same meaning. The sentiment analyser has read the word 'awfully' and prescribed a negative sentiment that a human translator – who would understand the context of this phrase – would not.\n",
        "\n",
        "> Additionally, this extract also illustrates the reduced accuracy of the machine translators, since when referring to a family in French it is correct to express their name in the singular form: so “les Tuñon” rather than “les Tuñons”.\n"
      ],
      "metadata": {
        "id": "xDGT6d4MD-wk"
      },
      "id": "xDGT6d4MD-wk"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Analysis\n",
        "\n",
        "First, download the two dataset the notebook is setup to run against '[machine-text.txt](https://github.com/ic-lester/French-sentiment-analysis-/blob/main/machine-text.txt)' and '[Human-Text.txt](https://github.com/ic-lester/French-sentiment-analysis-/blob/main/Human-Text.txt)'. These contain 300 or so lines of text translation from English to French (roughly 8,000 words each).\n",
        "\n",
        "**Note**: hit the `Raw` button on Github to access these files, after which you may need to right/cmd click to download.\n",
        "\n",
        "Then in the Colaboratory Notebook sidebar on the left of the screen, select Files (the folder icon), hit the upload icon, and upload your chose to your notebook. Once the file appears in the sidebar you are ready to go.\n",
        "\n",
        "**Note**: if you upload files other than these be sure to change the file names in the cells below before you run the cells."
      ],
      "metadata": {
        "id": "tMbmzIopoa1U"
      },
      "id": "tMbmzIopoa1U"
    },
    {
      "cell_type": "markdown",
      "source": [
        "These two step open our text files `machine_text.txt` and `Human_text.txt` and put them into their respective message_text variables for use in various analysis functions below."
      ],
      "metadata": {
        "id": "tzTQhfAza8x0"
      },
      "id": "tzTQhfAza8x0"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "54ca1275",
      "metadata": {
        "id": "54ca1275"
      },
      "outputs": [],
      "source": [
        "dataMT = open('machine-text.txt', encoding=\"utf-8\")\n",
        "message_textMT = dataMT.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "0872912a",
      "metadata": {
        "id": "0872912a"
      },
      "outputs": [],
      "source": [
        "dataHT = open('Human-Text.txt', encoding=\"utf-8\")\n",
        "message_textHT = dataHT.read()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initial Data Analysis"
      ],
      "metadata": {
        "id": "xK-_QBq2qopt"
      },
      "id": "xK-_QBq2qopt"
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "f63517cb",
      "metadata": {
        "id": "f63517cb"
      },
      "outputs": [],
      "source": [
        "scoresMT = SIA.polarity_scores(message_textMT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "f280b8e1",
      "metadata": {
        "id": "f280b8e1"
      },
      "outputs": [],
      "source": [
        "scoresHT = SIA.polarity_scores(message_textHT)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the steps above, we have created variables that contain sentiment analysis scores for each text."
      ],
      "metadata": {
        "id": "8PH3B_dmq6-f"
      },
      "id": "8PH3B_dmq6-f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1ba5638",
      "metadata": {
        "id": "a1ba5638"
      },
      "outputs": [],
      "source": [
        "scoresMT\n",
        "\n",
        "for key in sorted(scoresMT):\n",
        "        print('{0}: {1}, '.format(key, scoresMT[key]), end='')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb990fba",
      "metadata": {
        "id": "bb990fba"
      },
      "outputs": [],
      "source": [
        "scoresHT\n",
        "\n",
        "for key in sorted(scoresHT):\n",
        "        print('{0}: {1}, '.format(key, scoresHT[key]), end='')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1e823e7",
      "metadata": {
        "id": "c1e823e7"
      },
      "source": [
        "When we print the respective scores for each text (above), we will get the texts' polarity and intensity scores. We can see that VADER scores human translations as very slightly more positive than the equivalent machine translations. Remember, the closer the `compound` score is to +1, the higher the more positive VADER is claiming the text to be."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "33f8fa7b",
      "metadata": {
        "id": "33f8fa7b"
      },
      "source": [
        "### Sentence level analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "More meaningful, however, might be to analyse this data line-by-line."
      ],
      "metadata": {
        "id": "23xK-w_Vi3bk"
      },
      "id": "23xK-w_Vi3bk"
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "5d3b8ba1",
      "metadata": {
        "id": "5d3b8ba1"
      },
      "outputs": [],
      "source": [
        "tokenizer = nltk.data.load('tokenizers/punkt/french.pickle')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "138d606c",
      "metadata": {
        "id": "138d606c"
      },
      "source": [
        "As previously explained, a tokenizer breaks down a text into smaller components. In this stage we create a `tokenizer` variable using french package within the `punkt` tokenizer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "d76617de",
      "metadata": {
        "id": "d76617de"
      },
      "outputs": [],
      "source": [
        "sentencesMT = tokenizer.tokenize(message_textMT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "54ed7d93",
      "metadata": {
        "id": "54ed7d93"
      },
      "outputs": [],
      "source": [
        "sentencesHT = tokenizer.tokenize(message_textHT)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "33f6202f",
      "metadata": {
        "id": "33f6202f"
      },
      "source": [
        "In the two steps above, we tokenize the two text and creating their `sentences` variables for each. These contain the text broken down sentences (one per line)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b88dfa9f",
      "metadata": {
        "id": "b88dfa9f"
      },
      "outputs": [],
      "source": [
        "for sentence in sentencesMT:\n",
        "        scores = SIA.polarity_scores(sentence)\n",
        "        print(sentence)\n",
        "        for key in sorted(scores):\n",
        "                print('{0}: {1}, '.format(key, scores[key]), end='')\n",
        "        print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d89d062",
      "metadata": {
        "id": "5d89d062"
      },
      "outputs": [],
      "source": [
        "for sentence in sentencesHT:\n",
        "        scores = SIA.polarity_scores(sentence)\n",
        "        print(sentence)\n",
        "        for key in sorted(scores):\n",
        "                print('{0}: {1}, '.format(key, scores[key]), end='')\n",
        "        print()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "51895595",
      "metadata": {
        "id": "51895595"
      },
      "source": [
        "Finally, in these two steps, `SentimentIntensityAnalyzer` loops through each text sentence by sentence and calculates their polarity and intensity scores. For each sentence, we then print a negative (`neg`), neutral (`neu`), positive (`pos`), and compound (combined) score."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This gives us pairs of texts analysed by sentiment, that we can then read for differences - either in the language, or in the sentiment analysis.\n",
        "\n",
        "As [Isobel found](https://github.com/Southampton-Digital-Humanities/2022_french-sentiment-analysis/blob/main/2022-08_Lester-I_nlp-report.pdf) (p12), VADER read the human translated texts as carrying more emotion than the machine translated texts.\n",
        "\n",
        "However, what Isobel also found (p15) is that we need to be careful before we trust the machine learning output, especially from rule based models like VADER, where we are not in the loop to iterate and check assumptions the model is making."
      ],
      "metadata": {
        "id": "SNP76coaCBF1"
      },
      "id": "SNP76coaCBF1"
    },
    {
      "cell_type": "markdown",
      "id": "736eb263",
      "metadata": {
        "id": "736eb263"
      },
      "source": [
        "### Rights"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook was produced by [James Baker](https://www.southampton.ac.uk/people/5yrbp5/doctor-james-baker) for the workshop '[START.. Analysing Sentiment with Python](https://www.eventbrite.co.uk/e/start-analysing-sentiment-with-python-tickets-428611417287?aff=ebdsoporgprofile)' held in November 2022, and organised by [Southampton Digital Humanities](http://digitalhumanities.soton.ac.uk/)."
      ],
      "metadata": {
        "id": "450OdTQkesYo"
      },
      "id": "450OdTQkesYo"
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook builds on Zoë Wilkinson Saldaña, \"Sentiment Analysis for Exploratory Data Analysis,\" *Programming Historian* 7 (2018), [https://doi.org/10.46430/phen0079](https://doi.org/10.46430/phen0079)."
      ],
      "metadata": {
        "id": "75ARNcWLet24"
      },
      "id": "75ARNcWLet24"
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook is released under a [CC-BY](https://creativecommons.org/licenses/by/4.0/deed.en) license."
      ],
      "metadata": {
        "id": "_zRIQwtPevwy"
      },
      "id": "_zRIQwtPevwy"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}